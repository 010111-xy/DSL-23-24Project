{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "development = pd.read_csv(\"./../DSL_Winter_Project_2024/development.csv\")\n",
    "evaluation = pd.read_csv(\"./../DSL_Winter_Project_2024/evaluation.csv\")\n",
    "\n",
    "# Outliers have been known from previous analysis\n",
    "outlier_column_index=[0, 7, 12, 15, 16, 17]\n",
    "columns_to_drop=[]\n",
    "\n",
    "for index in outlier_column_index:\n",
    "    columns_to_drop.append('pmax[%s]' % index)\n",
    "    columns_to_drop.append('negpmax[%s]' % index)\n",
    "    columns_to_drop.append('tmax[%s]' % index)\n",
    "    columns_to_drop.append('area[%s]' % index)\n",
    "    columns_to_drop.append('rms[%s]' % index)\n",
    "\n",
    "dev_df=development.drop(columns=columns_to_drop)\n",
    "eva_df=evaluation.drop(columns=columns_to_drop)\n",
    "eva_df=eva_df.drop(columns=[\"Id\"])\n",
    "\n",
    "X=dev_df.drop(columns=['x', 'y'])\n",
    "y=dev_df.loc[:,['x', 'y']]\n",
    "rs=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 36121.3906 - val_loss: 3326.0532\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 744.3203 - val_loss: 54.5026\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 477us/step - loss: 34.1684 - val_loss: 35.5989\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 26.8506 - val_loss: 28.7888\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 23.5371 - val_loss: 24.8251\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 21.6698 - val_loss: 23.9111\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 20.2351 - val_loss: 23.5579\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 19.0806 - val_loss: 21.7137\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 18.3771 - val_loss: 21.6108\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 17.6943 - val_loss: 20.7856\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 17.2043 - val_loss: 20.3594\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 16.7668 - val_loss: 20.1893\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 16.4306 - val_loss: 19.6719\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 500us/step - loss: 16.1435 - val_loss: 19.5704\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 502us/step - loss: 15.9044 - val_loss: 20.0044\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 15.6199 - val_loss: 19.1419\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 467us/step - loss: 15.3109 - val_loss: 19.1130\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 461us/step - loss: 15.1006 - val_loss: 18.9274\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 14.9444 - val_loss: 18.7063\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 14.6566 - val_loss: 18.5925\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 14.5235 - val_loss: 18.5738\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 14.4071 - val_loss: 19.0363\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 497us/step - loss: 14.1321 - val_loss: 17.9570\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 499us/step - loss: 14.0958 - val_loss: 18.3863\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 13.9940 - val_loss: 18.6172\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 501us/step - loss: 13.8916 - val_loss: 18.7223\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 492us/step - loss: 13.7179 - val_loss: 18.0267\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.6841 - val_loss: 18.0281\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.6722 - val_loss: 17.9728\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.5642 - val_loss: 19.0802\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 13.4745 - val_loss: 18.0003\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 500us/step - loss: 13.3454 - val_loss: 17.8449\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 13.2748 - val_loss: 17.9827\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 13.2354 - val_loss: 18.1135\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 487us/step - loss: 13.1849 - val_loss: 18.1263\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 492us/step - loss: 13.0857 - val_loss: 17.4032\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 13.0644 - val_loss: 17.4300\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 12.9433 - val_loss: 17.5418\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 12.9335 - val_loss: 18.0020\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 12.8143 - val_loss: 17.8487\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 12.8829 - val_loss: 18.4897\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 12.6896 - val_loss: 17.9726\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 494us/step - loss: 12.7261 - val_loss: 18.1095\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 463us/step - loss: 12.6822 - val_loss: 18.1289\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 460us/step - loss: 12.5728 - val_loss: 17.6661\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 4s 469us/step - loss: 12.5588 - val_loss: 17.5613\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 12.5741 - val_loss: 17.7652\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 12.4725 - val_loss: 17.7241\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 12.4022 - val_loss: 17.5913\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 12.4088 - val_loss: 17.2829\n",
      "2410/2410 [==============================] - 1s 245us/step\n",
      "4.2332971267991395\n"
     ]
    }
   ],
   "source": [
    "# normalized data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# set the parameters to normal values to see the model effect.\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 506us/step - loss: 36518.9766 - mae: 140.9164 - acc: 0.6997 - val_loss: 3259.9126 - val_mae: 41.3758 - val_acc: 0.9814\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 735.8427 - mae: 14.1608 - acc: 0.9852 - val_loss: 56.2554 - val_mae: 4.3699 - val_acc: 0.9864\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 35.2692 - mae: 3.8106 - acc: 0.9864 - val_loss: 37.2252 - val_mae: 3.5812 - val_acc: 0.9873\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 27.7881 - mae: 3.4778 - acc: 0.9871 - val_loss: 30.9284 - val_mae: 3.3801 - val_acc: 0.9878\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 24.6439 - mae: 3.3287 - acc: 0.9875 - val_loss: 27.9025 - val_mae: 3.3196 - val_acc: 0.9871\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 475us/step - loss: 22.6843 - mae: 3.2229 - acc: 0.9876 - val_loss: 25.3090 - val_mae: 3.1928 - val_acc: 0.9888\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 4s 469us/step - loss: 21.4809 - mae: 3.1487 - acc: 0.9881 - val_loss: 25.1620 - val_mae: 3.1372 - val_acc: 0.9886\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 20.1940 - mae: 3.0885 - acc: 0.9883 - val_loss: 22.9248 - val_mae: 3.0696 - val_acc: 0.9885\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 4s 469us/step - loss: 19.2390 - mae: 3.0375 - acc: 0.9885 - val_loss: 22.9496 - val_mae: 3.0485 - val_acc: 0.9893\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 499us/step - loss: 18.3992 - mae: 2.9948 - acc: 0.9886 - val_loss: 23.2714 - val_mae: 3.0718 - val_acc: 0.9896\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 4s 499us/step - loss: 17.8212 - mae: 2.9642 - acc: 0.9886 - val_loss: 22.5359 - val_mae: 2.9762 - val_acc: 0.9895\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 17.3594 - mae: 2.9361 - acc: 0.9888 - val_loss: 22.1453 - val_mae: 2.9774 - val_acc: 0.9877\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 477us/step - loss: 16.9767 - mae: 2.9111 - acc: 0.9886 - val_loss: 21.3873 - val_mae: 2.9450 - val_acc: 0.9890\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 523us/step - loss: 16.6274 - mae: 2.8897 - acc: 0.9889 - val_loss: 20.2691 - val_mae: 2.8860 - val_acc: 0.9886\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 511us/step - loss: 16.2863 - mae: 2.8718 - acc: 0.9888 - val_loss: 20.2784 - val_mae: 2.8856 - val_acc: 0.9886\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 15.9664 - mae: 2.8522 - acc: 0.9891 - val_loss: 20.7550 - val_mae: 2.9183 - val_acc: 0.9895\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 15.7608 - mae: 2.8395 - acc: 0.9890 - val_loss: 19.6317 - val_mae: 2.8604 - val_acc: 0.9888\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 15.4761 - mae: 2.8261 - acc: 0.9890 - val_loss: 19.2152 - val_mae: 2.8488 - val_acc: 0.9891\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 478us/step - loss: 15.3405 - mae: 2.8112 - acc: 0.9894 - val_loss: 19.5089 - val_mae: 2.8803 - val_acc: 0.9899\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 15.1284 - mae: 2.7978 - acc: 0.9891 - val_loss: 18.9410 - val_mae: 2.8534 - val_acc: 0.9896\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 14.9348 - mae: 2.7872 - acc: 0.9892 - val_loss: 18.7632 - val_mae: 2.8252 - val_acc: 0.9899\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 475us/step - loss: 14.8229 - mae: 2.7781 - acc: 0.9891 - val_loss: 18.7793 - val_mae: 2.8094 - val_acc: 0.9879\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 14.6227 - mae: 2.7663 - acc: 0.9893 - val_loss: 18.5359 - val_mae: 2.8205 - val_acc: 0.9895\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 14.4626 - mae: 2.7580 - acc: 0.9891 - val_loss: 19.6363 - val_mae: 2.9470 - val_acc: 0.9887\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 14.4010 - mae: 2.7515 - acc: 0.9894 - val_loss: 19.5608 - val_mae: 2.8591 - val_acc: 0.9901\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 14.2629 - mae: 2.7419 - acc: 0.9894 - val_loss: 17.9883 - val_mae: 2.7810 - val_acc: 0.9896\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 477us/step - loss: 14.1844 - mae: 2.7356 - acc: 0.9893 - val_loss: 18.1778 - val_mae: 2.7806 - val_acc: 0.9897\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 13.9778 - mae: 2.7258 - acc: 0.9893 - val_loss: 18.1037 - val_mae: 2.7799 - val_acc: 0.9898\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 505us/step - loss: 13.8566 - mae: 2.7190 - acc: 0.9893 - val_loss: 18.0584 - val_mae: 2.7863 - val_acc: 0.9884\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 13.8155 - mae: 2.7147 - acc: 0.9894 - val_loss: 18.5270 - val_mae: 2.7872 - val_acc: 0.9896\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 497us/step - loss: 13.6580 - mae: 2.7057 - acc: 0.9893 - val_loss: 18.3655 - val_mae: 2.8175 - val_acc: 0.9897\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 509us/step - loss: 13.6743 - mae: 2.7009 - acc: 0.9894 - val_loss: 18.1696 - val_mae: 2.7797 - val_acc: 0.9898\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 13.6107 - mae: 2.6925 - acc: 0.9894 - val_loss: 17.8189 - val_mae: 2.7439 - val_acc: 0.9901\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 13.4593 - mae: 2.6871 - acc: 0.9894 - val_loss: 17.5726 - val_mae: 2.7167 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 13.3691 - mae: 2.6792 - acc: 0.9894 - val_loss: 18.1935 - val_mae: 2.7372 - val_acc: 0.9899\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 13.3726 - mae: 2.6750 - acc: 0.9893 - val_loss: 17.4072 - val_mae: 2.7354 - val_acc: 0.9896\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.1878 - mae: 2.6698 - acc: 0.9896 - val_loss: 17.9062 - val_mae: 2.7458 - val_acc: 0.9892\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 475us/step - loss: 13.1399 - mae: 2.6677 - acc: 0.9894 - val_loss: 17.6638 - val_mae: 2.7392 - val_acc: 0.9897\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 477us/step - loss: 13.1214 - mae: 2.6619 - acc: 0.9896 - val_loss: 18.1724 - val_mae: 2.7595 - val_acc: 0.9900\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 13.0329 - mae: 2.6563 - acc: 0.9894 - val_loss: 18.5555 - val_mae: 2.8077 - val_acc: 0.9891\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 12.9502 - mae: 2.6513 - acc: 0.9896 - val_loss: 17.9533 - val_mae: 2.7171 - val_acc: 0.9898\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 506us/step - loss: 12.9328 - mae: 2.6495 - acc: 0.9896 - val_loss: 17.7984 - val_mae: 2.7236 - val_acc: 0.9894\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 503us/step - loss: 12.8336 - mae: 2.6444 - acc: 0.9896 - val_loss: 17.9212 - val_mae: 2.7600 - val_acc: 0.9893\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 496us/step - loss: 12.7959 - mae: 2.6404 - acc: 0.9897 - val_loss: 17.7224 - val_mae: 2.7134 - val_acc: 0.9895\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 518us/step - loss: 12.7506 - mae: 2.6340 - acc: 0.9896 - val_loss: 17.7234 - val_mae: 2.7231 - val_acc: 0.9900\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 12.7395 - mae: 2.6347 - acc: 0.9896 - val_loss: 17.5421 - val_mae: 2.7265 - val_acc: 0.9908\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 12.6699 - mae: 2.6296 - acc: 0.9896 - val_loss: 17.6335 - val_mae: 2.7027 - val_acc: 0.9907\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 506us/step - loss: 12.5582 - mae: 2.6232 - acc: 0.9895 - val_loss: 17.6396 - val_mae: 2.6955 - val_acc: 0.9890\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 501us/step - loss: 12.5947 - mae: 2.6219 - acc: 0.9896 - val_loss: 17.6387 - val_mae: 2.6976 - val_acc: 0.9903\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 496us/step - loss: 12.5441 - mae: 2.6200 - acc: 0.9897 - val_loss: 17.6468 - val_mae: 2.6818 - val_acc: 0.9903\n",
      "2410/2410 [==============================] - 1s 268us/step\n",
      "4.181203413941417\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4016/4016 [==============================] - 1s 256us/step\n"
     ]
    }
   ],
   "source": [
    "eva_df_scaled = scaler.transform(eva_df)\n",
    "\n",
    "eva_y=model.predict(eva_df_scaled)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('tensor_output1.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMaxScaler is not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 513us/step - loss: 42320.2539 - mae: 164.0027 - acc: 0.5200 - val_loss: 13718.3223 - val_mae: 100.4028 - val_acc: 0.5218\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 5580.7534 - mae: 52.1360 - acc: 0.8182 - val_loss: 249.4449 - val_mae: 10.1418 - val_acc: 0.9776\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 82.8928 - mae: 6.2532 - acc: 0.9803 - val_loss: 46.0678 - val_mae: 5.1367 - val_acc: 0.9823\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 478us/step - loss: 40.9770 - mae: 4.8438 - acc: 0.9826 - val_loss: 37.5230 - val_mae: 4.6528 - val_acc: 0.9839\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 4s 467us/step - loss: 36.5249 - mae: 4.5997 - acc: 0.9830 - val_loss: 34.8087 - val_mae: 4.4972 - val_acc: 0.9817\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 34.3203 - mae: 4.4742 - acc: 0.9833 - val_loss: 33.3961 - val_mae: 4.4218 - val_acc: 0.9815\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 32.9617 - mae: 4.3893 - acc: 0.9840 - val_loss: 32.5892 - val_mae: 4.3730 - val_acc: 0.9833\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 31.9580 - mae: 4.3241 - acc: 0.9844 - val_loss: 32.5892 - val_mae: 4.3480 - val_acc: 0.9837\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 31.1842 - mae: 4.2766 - acc: 0.9846 - val_loss: 29.8942 - val_mae: 4.1824 - val_acc: 0.9845\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 30.6332 - mae: 4.2403 - acc: 0.9847 - val_loss: 30.2781 - val_mae: 4.2182 - val_acc: 0.9836\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 4s 467us/step - loss: 30.0495 - mae: 4.2014 - acc: 0.9850 - val_loss: 30.8512 - val_mae: 4.2612 - val_acc: 0.9808\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 4s 478us/step - loss: 29.6194 - mae: 4.1724 - acc: 0.9849 - val_loss: 30.1398 - val_mae: 4.2103 - val_acc: 0.9843\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 29.2571 - mae: 4.1486 - acc: 0.9851 - val_loss: 28.4116 - val_mae: 4.0855 - val_acc: 0.9836\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 495us/step - loss: 28.9049 - mae: 4.1247 - acc: 0.9852 - val_loss: 28.5228 - val_mae: 4.0970 - val_acc: 0.9860\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 28.5587 - mae: 4.1010 - acc: 0.9851 - val_loss: 27.8471 - val_mae: 4.0462 - val_acc: 0.9849\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 28.2686 - mae: 4.0788 - acc: 0.9855 - val_loss: 27.4939 - val_mae: 4.0238 - val_acc: 0.9852\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 28.0044 - mae: 4.0604 - acc: 0.9855 - val_loss: 28.1617 - val_mae: 4.0740 - val_acc: 0.9856\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 27.8067 - mae: 4.0467 - acc: 0.9855 - val_loss: 27.3874 - val_mae: 4.0170 - val_acc: 0.9845\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 27.5303 - mae: 4.0278 - acc: 0.9854 - val_loss: 27.0390 - val_mae: 3.9882 - val_acc: 0.9857\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 27.3366 - mae: 4.0147 - acc: 0.9854 - val_loss: 26.7996 - val_mae: 3.9675 - val_acc: 0.9848\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 27.1328 - mae: 3.9977 - acc: 0.9856 - val_loss: 26.7600 - val_mae: 3.9684 - val_acc: 0.9869\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 499us/step - loss: 26.9853 - mae: 3.9894 - acc: 0.9857 - val_loss: 26.6921 - val_mae: 3.9649 - val_acc: 0.9852\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 26.8010 - mae: 3.9718 - acc: 0.9857 - val_loss: 29.4320 - val_mae: 4.1418 - val_acc: 0.9857\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 26.6483 - mae: 3.9627 - acc: 0.9855 - val_loss: 26.2632 - val_mae: 3.9300 - val_acc: 0.9863\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 26.4722 - mae: 3.9495 - acc: 0.9857 - val_loss: 26.5375 - val_mae: 3.9403 - val_acc: 0.9851\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 26.3751 - mae: 3.9418 - acc: 0.9857 - val_loss: 25.9531 - val_mae: 3.9050 - val_acc: 0.9868\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 26.2293 - mae: 3.9321 - acc: 0.9858 - val_loss: 26.4136 - val_mae: 3.9394 - val_acc: 0.9863\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 26.0822 - mae: 3.9207 - acc: 0.9857 - val_loss: 26.9351 - val_mae: 3.9892 - val_acc: 0.9861\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 25.9317 - mae: 3.9101 - acc: 0.9857 - val_loss: 25.5131 - val_mae: 3.8745 - val_acc: 0.9862\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 25.8380 - mae: 3.9025 - acc: 0.9857 - val_loss: 25.5259 - val_mae: 3.8736 - val_acc: 0.9864\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 25.6875 - mae: 3.8909 - acc: 0.9859 - val_loss: 24.9810 - val_mae: 3.8306 - val_acc: 0.9861\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 25.6111 - mae: 3.8853 - acc: 0.9857 - val_loss: 25.1219 - val_mae: 3.8424 - val_acc: 0.9865\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 496us/step - loss: 25.4894 - mae: 3.8767 - acc: 0.9860 - val_loss: 25.6733 - val_mae: 3.8872 - val_acc: 0.9864\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 25.3904 - mae: 3.8679 - acc: 0.9860 - val_loss: 26.0258 - val_mae: 3.9256 - val_acc: 0.9854\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 25.2891 - mae: 3.8609 - acc: 0.9858 - val_loss: 25.1487 - val_mae: 3.8392 - val_acc: 0.9847\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 25.1425 - mae: 3.8512 - acc: 0.9860 - val_loss: 25.4672 - val_mae: 3.8734 - val_acc: 0.9847\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 25.0727 - mae: 3.8454 - acc: 0.9859 - val_loss: 27.1215 - val_mae: 4.0083 - val_acc: 0.9827\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 24.9540 - mae: 3.8348 - acc: 0.9860 - val_loss: 25.2948 - val_mae: 3.8510 - val_acc: 0.9854\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 24.8797 - mae: 3.8305 - acc: 0.9859 - val_loss: 25.3400 - val_mae: 3.8661 - val_acc: 0.9872\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 24.7564 - mae: 3.8217 - acc: 0.9860 - val_loss: 24.6163 - val_mae: 3.8025 - val_acc: 0.9864\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 24.6619 - mae: 3.8144 - acc: 0.9861 - val_loss: 24.7914 - val_mae: 3.8198 - val_acc: 0.9862\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 24.5901 - mae: 3.8081 - acc: 0.9860 - val_loss: 24.3014 - val_mae: 3.7803 - val_acc: 0.9862\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 24.5105 - mae: 3.8012 - acc: 0.9860 - val_loss: 24.4802 - val_mae: 3.7976 - val_acc: 0.9869\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 24.4210 - mae: 3.7956 - acc: 0.9860 - val_loss: 24.9706 - val_mae: 3.8405 - val_acc: 0.9849\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 490us/step - loss: 24.3434 - mae: 3.7905 - acc: 0.9860 - val_loss: 25.1940 - val_mae: 3.8622 - val_acc: 0.9839\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 4s 490us/step - loss: 24.2537 - mae: 3.7833 - acc: 0.9861 - val_loss: 24.2957 - val_mae: 3.7827 - val_acc: 0.9856\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 24.1840 - mae: 3.7757 - acc: 0.9862 - val_loss: 24.6142 - val_mae: 3.8112 - val_acc: 0.9851\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 24.1022 - mae: 3.7724 - acc: 0.9862 - val_loss: 24.3055 - val_mae: 3.7809 - val_acc: 0.9868\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 24.0615 - mae: 3.7681 - acc: 0.9861 - val_loss: 24.2554 - val_mae: 3.7843 - val_acc: 0.9870\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 24.0201 - mae: 3.7661 - acc: 0.9861 - val_loss: 23.7557 - val_mae: 3.7394 - val_acc: 0.9862\n",
      "2410/2410 [==============================] - 1s 242us/step\n",
      "5.890410082861226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pmax and area are two features with linear correlation, but removing them here does not improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmax_features = []\n",
    "area_features = []\n",
    "\n",
    "for i in range(0, 18):\n",
    "    if(i in outlier_column_index):\n",
    "        continue\n",
    "    pmax_features.append(\"pmax[%s]\" % (i))\n",
    "    area_features.append(\"area[%s]\" % (i))\n",
    "\n",
    "X_train_drop_pmax = X_train.drop(columns=pmax_features + area_features)\n",
    "X_test_drop_pmax=X_test.drop(columns=pmax_features + area_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 5s 618us/step - loss: 37451.3320 - mae: 145.4534 - acc: 0.6329 - val_loss: 3946.4587 - val_mae: 48.1615 - val_acc: 0.9624\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 5s 588us/step - loss: 982.5688 - mae: 18.7409 - acc: 0.9713 - val_loss: 134.8243 - val_mae: 7.5034 - val_acc: 0.9760\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 5s 599us/step - loss: 109.7859 - mae: 6.6884 - acc: 0.9757 - val_loss: 100.2411 - val_mae: 6.3630 - val_acc: 0.9771\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 5s 592us/step - loss: 93.9059 - mae: 6.1261 - acc: 0.9765 - val_loss: 89.4347 - val_mae: 5.9818 - val_acc: 0.9784\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 5s 618us/step - loss: 86.8402 - mae: 5.8874 - acc: 0.9776 - val_loss: 82.6455 - val_mae: 5.7326 - val_acc: 0.9791\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 5s 599us/step - loss: 82.1001 - mae: 5.7223 - acc: 0.9783 - val_loss: 79.5731 - val_mae: 5.6445 - val_acc: 0.9797\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 5s 595us/step - loss: 78.4995 - mae: 5.6030 - acc: 0.9790 - val_loss: 82.6572 - val_mae: 5.8450 - val_acc: 0.9795\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 582us/step - loss: 75.7488 - mae: 5.5073 - acc: 0.9790 - val_loss: 74.1654 - val_mae: 5.4561 - val_acc: 0.9787\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 5s 593us/step - loss: 73.6616 - mae: 5.4331 - acc: 0.9796 - val_loss: 72.5866 - val_mae: 5.3816 - val_acc: 0.9805\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 583us/step - loss: 71.3375 - mae: 5.3651 - acc: 0.9798 - val_loss: 72.2979 - val_mae: 5.4003 - val_acc: 0.9805\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 5s 594us/step - loss: 69.7330 - mae: 5.3137 - acc: 0.9799 - val_loss: 70.6872 - val_mae: 5.2924 - val_acc: 0.9814\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 5s 598us/step - loss: 68.1750 - mae: 5.2698 - acc: 0.9802 - val_loss: 68.6884 - val_mae: 5.2239 - val_acc: 0.9805\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 571us/step - loss: 66.5559 - mae: 5.2239 - acc: 0.9804 - val_loss: 67.8776 - val_mae: 5.2133 - val_acc: 0.9813\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 577us/step - loss: 65.3331 - mae: 5.1835 - acc: 0.9806 - val_loss: 66.8167 - val_mae: 5.1858 - val_acc: 0.9803\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 573us/step - loss: 64.0550 - mae: 5.1519 - acc: 0.9806 - val_loss: 67.4862 - val_mae: 5.2374 - val_acc: 0.9815\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 575us/step - loss: 63.1833 - mae: 5.1183 - acc: 0.9806 - val_loss: 65.3473 - val_mae: 5.1348 - val_acc: 0.9797\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 582us/step - loss: 62.0845 - mae: 5.0853 - acc: 0.9806 - val_loss: 66.0108 - val_mae: 5.1874 - val_acc: 0.9810\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 5s 592us/step - loss: 61.3779 - mae: 5.0593 - acc: 0.9808 - val_loss: 64.3023 - val_mae: 5.0822 - val_acc: 0.9805\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 60.5679 - mae: 5.0368 - acc: 0.9811 - val_loss: 63.4414 - val_mae: 5.0631 - val_acc: 0.9814\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 5s 600us/step - loss: 59.7034 - mae: 5.0044 - acc: 0.9811 - val_loss: 62.5945 - val_mae: 5.0272 - val_acc: 0.9810\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 5s 594us/step - loss: 59.0291 - mae: 4.9822 - acc: 0.9813 - val_loss: 62.1418 - val_mae: 5.0157 - val_acc: 0.9808\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 5s 590us/step - loss: 58.0533 - mae: 4.9589 - acc: 0.9812 - val_loss: 62.0078 - val_mae: 5.0174 - val_acc: 0.9817\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 550us/step - loss: 57.4474 - mae: 4.9447 - acc: 0.9816 - val_loss: 61.4870 - val_mae: 5.0102 - val_acc: 0.9810\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 554us/step - loss: 56.6592 - mae: 4.9228 - acc: 0.9816 - val_loss: 60.8418 - val_mae: 4.9744 - val_acc: 0.9817\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 542us/step - loss: 55.9896 - mae: 4.9032 - acc: 0.9817 - val_loss: 59.8794 - val_mae: 4.9593 - val_acc: 0.9822\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 564us/step - loss: 55.1626 - mae: 4.8863 - acc: 0.9817 - val_loss: 59.2655 - val_mae: 4.9041 - val_acc: 0.9822\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 555us/step - loss: 54.4994 - mae: 4.8702 - acc: 0.9816 - val_loss: 59.4096 - val_mae: 4.9432 - val_acc: 0.9817\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 538us/step - loss: 53.8632 - mae: 4.8561 - acc: 0.9820 - val_loss: 59.1065 - val_mae: 4.9195 - val_acc: 0.9816\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 524us/step - loss: 53.2934 - mae: 4.8378 - acc: 0.9820 - val_loss: 58.0731 - val_mae: 4.8829 - val_acc: 0.9824\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 534us/step - loss: 52.8072 - mae: 4.8238 - acc: 0.9819 - val_loss: 57.4550 - val_mae: 4.8537 - val_acc: 0.9829\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 536us/step - loss: 52.3160 - mae: 4.8100 - acc: 0.9822 - val_loss: 58.1926 - val_mae: 4.9128 - val_acc: 0.9812\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 535us/step - loss: 51.7713 - mae: 4.7965 - acc: 0.9823 - val_loss: 58.0547 - val_mae: 4.9160 - val_acc: 0.9817\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 560us/step - loss: 51.5679 - mae: 4.7838 - acc: 0.9822 - val_loss: 56.7542 - val_mae: 4.8398 - val_acc: 0.9826\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 568us/step - loss: 51.0193 - mae: 4.7709 - acc: 0.9823 - val_loss: 56.4175 - val_mae: 4.8152 - val_acc: 0.9825\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 560us/step - loss: 50.7590 - mae: 4.7597 - acc: 0.9824 - val_loss: 56.2639 - val_mae: 4.8118 - val_acc: 0.9827\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 543us/step - loss: 50.7028 - mae: 4.7481 - acc: 0.9823 - val_loss: 56.1487 - val_mae: 4.7920 - val_acc: 0.9822\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 553us/step - loss: 50.1438 - mae: 4.7341 - acc: 0.9824 - val_loss: 57.1377 - val_mae: 4.8672 - val_acc: 0.9827\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 550us/step - loss: 49.7803 - mae: 4.7292 - acc: 0.9823 - val_loss: 55.4635 - val_mae: 4.7619 - val_acc: 0.9825\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 549us/step - loss: 49.4926 - mae: 4.7194 - acc: 0.9822 - val_loss: 55.4772 - val_mae: 4.7702 - val_acc: 0.9827\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 554us/step - loss: 49.2304 - mae: 4.7117 - acc: 0.9824 - val_loss: 55.3849 - val_mae: 4.7883 - val_acc: 0.9821\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 549us/step - loss: 48.8288 - mae: 4.6973 - acc: 0.9823 - val_loss: 57.2063 - val_mae: 4.9206 - val_acc: 0.9830\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 553us/step - loss: 48.6576 - mae: 4.6897 - acc: 0.9825 - val_loss: 54.7840 - val_mae: 4.7783 - val_acc: 0.9826\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 550us/step - loss: 48.2357 - mae: 4.6818 - acc: 0.9825 - val_loss: 55.0686 - val_mae: 4.8069 - val_acc: 0.9831\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 583us/step - loss: 47.9963 - mae: 4.6735 - acc: 0.9824 - val_loss: 53.6677 - val_mae: 4.7173 - val_acc: 0.9829\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 578us/step - loss: 47.8517 - mae: 4.6619 - acc: 0.9827 - val_loss: 53.6511 - val_mae: 4.7328 - val_acc: 0.9826\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 5s 588us/step - loss: 47.5228 - mae: 4.6576 - acc: 0.9827 - val_loss: 53.3111 - val_mae: 4.7229 - val_acc: 0.9832\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 577us/step - loss: 47.2418 - mae: 4.6497 - acc: 0.9826 - val_loss: 53.9495 - val_mae: 4.7352 - val_acc: 0.9822\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 583us/step - loss: 47.1722 - mae: 4.6398 - acc: 0.9826 - val_loss: 54.0480 - val_mae: 4.7698 - val_acc: 0.9831\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 5s 586us/step - loss: 46.7477 - mae: 4.6345 - acc: 0.9826 - val_loss: 53.9695 - val_mae: 4.7459 - val_acc: 0.9830\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 5s 587us/step - loss: 46.5069 - mae: 4.6249 - acc: 0.9827 - val_loss: 52.6389 - val_mae: 4.7088 - val_acc: 0.9832\n",
      "2410/2410 [==============================] - 1s 289us/step\n",
      "7.347435658739749\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_drop_pmax)\n",
    "X_test_scaled = scaler.transform(X_test_drop_pmax)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train_drop_pmax.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=5, step=1)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "                               activation='sigmoid'))\n",
    "        model.add(layers.Dropout(rate=hp.Float('dropout_' + str(i), min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(layers.Dense(units=2))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae', 'acc'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True,\n",
    "    directory='my_tuning_directory',\n",
    "    project_name='my_first_tuning_project'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "\n",
    "best_hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
