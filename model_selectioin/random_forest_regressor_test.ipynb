{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "development = pd.read_csv(\"./../../DSL_Winter_Project_2024/development.csv\")\n",
    "\n",
    "outlier_column_index=[0, 7, 12, 15, 16, 17]\n",
    "columns_to_drop=[]\n",
    "\n",
    "for index in outlier_column_index:\n",
    "    columns_to_drop.append('pmax[%s]' % index)\n",
    "    columns_to_drop.append('negpmax[%s]' % index)\n",
    "    columns_to_drop.append('tmax[%s]' % index)\n",
    "    columns_to_drop.append('area[%s]' % index)\n",
    "    columns_to_drop.append('rms[%s]' % index)\n",
    "\n",
    "evaluation = pd.read_csv(\"./../../DSL_Winter_Project_2024/evaluation.csv\")\n",
    "eva=evaluation.drop(columns=columns_to_drop)\n",
    "eva_df=eva.drop(columns=[\"Id\"])\n",
    "\n",
    "df=development.drop(columns=columns_to_drop)\n",
    "X=df.drop(columns=['x', 'y'])\n",
    "y=df.loc[:,['x', 'y']]\n",
    "\n",
    "rs=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}\n",
    "\n",
    "output0.csv\n",
    "\n",
    "distance: 4.576920443421794 (5.122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.576920443421794\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=100,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=None,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "y_rfr=rfr.predict(X_test)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "eva_y=rfr.predict(eva_df)\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output0.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 260, 'min_samples_split': 50, 'min_samples_leaf': 50, 'max_features': 'sqrt', 'max_depth': 100}\n",
    "\n",
    "output1.csv\n",
    "\n",
    "distance: 5.929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.563470114295041\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=260,min_samples_split=50,min_samples_leaf=50,max_features='sqrt',max_depth=100,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "eva_y=rfr.predict(eva_df)\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output1.csv', index=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 50}\n",
    "\n",
    "output2.csv\n",
    "\n",
    "distance: 5.031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.494897256772761\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=200,min_samples_split=5,min_samples_leaf=1,max_features='sqrt',max_depth=50,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output2.csv', index=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.441804259159674\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=500,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=150,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output3.csv', index=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.501637990431042\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=200,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=20,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output4.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 350, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.472743778568188\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=350,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=20,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output5.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 490, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.442287968155777\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=490,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=None,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output6.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4497516078756485\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=490,min_samples_split=5,min_samples_leaf=1,max_features='sqrt',max_depth=50,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output7.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 495, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 45}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.460348824798174\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=495,min_samples_split=2,min_samples_leaf=2,max_features='sqrt',max_depth=45,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output8.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 550, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.438729011590766\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=550,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=150,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output9.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.426690679410952\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=800,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=150,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output10.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.420698153416437\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=1200,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=200,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output11.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.412443094058066\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=3000,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=200,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output12.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 5149.0020 - val_loss: 2198.6707\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 789.8791 - val_loss: 769.4656\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 475us/step - loss: 137.9995 - val_loss: 825.5518\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 80.2341 - val_loss: 934.8686\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 95.9943 - val_loss: 1189.6565\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 69.4150 - val_loss: 1065.1541\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 3s 454us/step - loss: 81.0731 - val_loss: 1135.2229\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 3s 450us/step - loss: 66.1952 - val_loss: 1027.7122\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 60.0229 - val_loss: 926.1052\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 455us/step - loss: 66.3857 - val_loss: 768.6426\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 43.4893 - val_loss: 1019.6464\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 3s 452us/step - loss: 42.6728 - val_loss: 696.1090\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 42.4901 - val_loss: 791.2830\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 35.9863 - val_loss: 687.8557\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 459us/step - loss: 35.5585 - val_loss: 653.8782\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 30.6552 - val_loss: 523.4903\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 32.1942 - val_loss: 615.4139\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 29.5932 - val_loss: 563.9923\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 32.3905 - val_loss: 310.9142\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 462us/step - loss: 26.2670 - val_loss: 248.1516\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 3s 452us/step - loss: 28.4238 - val_loss: 704.7885\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 29.2744 - val_loss: 473.3849\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 27.8980 - val_loss: 531.2765\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 458us/step - loss: 27.0438 - val_loss: 731.5786\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 463us/step - loss: 28.0615 - val_loss: 487.5953\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 458us/step - loss: 26.8529 - val_loss: 512.9246\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 26.6459 - val_loss: 319.9047\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 3s 448us/step - loss: 24.2819 - val_loss: 305.8122\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 26.9507 - val_loss: 670.9254\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 459us/step - loss: 25.8065 - val_loss: 426.2496\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 510us/step - loss: 24.9829 - val_loss: 310.7433\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 23.0163 - val_loss: 641.5978\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 25.1210 - val_loss: 636.9828\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 26.0148 - val_loss: 335.3322\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 27.6922 - val_loss: 574.4395\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 23.9047 - val_loss: 330.1531\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 24.2720 - val_loss: 262.2712\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 477us/step - loss: 24.5411 - val_loss: 388.4242\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 462us/step - loss: 22.1053 - val_loss: 762.4196\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 462us/step - loss: 20.8033 - val_loss: 415.4099\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 460us/step - loss: 24.9759 - val_loss: 267.1811\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 455us/step - loss: 21.9488 - val_loss: 442.6662\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 21.2070 - val_loss: 376.4264\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 22.2530 - val_loss: 611.5332\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 455us/step - loss: 23.6958 - val_loss: 390.5405\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 3s 452us/step - loss: 22.4950 - val_loss: 490.2391\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 456us/step - loss: 22.6665 - val_loss: 432.1601\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 22.3661 - val_loss: 256.3332\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 3s 447us/step - loss: 21.6308 - val_loss: 361.7976\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 23.0559 - val_loss: 569.6152\n",
      "2410/2410 [==============================] - 1s 248us/step\n"
     ]
    }
   ],
   "source": [
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)  # 输出层，2个神经元对应 x 和 y\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='relu', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.29618979662101\n"
     ]
    }
   ],
   "source": [
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 36121.3906 - val_loss: 3326.0532\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 744.3203 - val_loss: 54.5026\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 477us/step - loss: 34.1684 - val_loss: 35.5989\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 26.8506 - val_loss: 28.7888\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 23.5371 - val_loss: 24.8251\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 21.6698 - val_loss: 23.9111\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 20.2351 - val_loss: 23.5579\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 19.0806 - val_loss: 21.7137\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 18.3771 - val_loss: 21.6108\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 17.6943 - val_loss: 20.7856\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 17.2043 - val_loss: 20.3594\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 16.7668 - val_loss: 20.1893\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 16.4306 - val_loss: 19.6719\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 500us/step - loss: 16.1435 - val_loss: 19.5704\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 502us/step - loss: 15.9044 - val_loss: 20.0044\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 15.6199 - val_loss: 19.1419\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 467us/step - loss: 15.3109 - val_loss: 19.1130\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 461us/step - loss: 15.1006 - val_loss: 18.9274\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 14.9444 - val_loss: 18.7063\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 14.6566 - val_loss: 18.5925\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 14.5235 - val_loss: 18.5738\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 14.4071 - val_loss: 19.0363\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 497us/step - loss: 14.1321 - val_loss: 17.9570\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 499us/step - loss: 14.0958 - val_loss: 18.3863\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 13.9940 - val_loss: 18.6172\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 501us/step - loss: 13.8916 - val_loss: 18.7223\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 492us/step - loss: 13.7179 - val_loss: 18.0267\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.6841 - val_loss: 18.0281\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.6722 - val_loss: 17.9728\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.5642 - val_loss: 19.0802\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 13.4745 - val_loss: 18.0003\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 500us/step - loss: 13.3454 - val_loss: 17.8449\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 13.2748 - val_loss: 17.9827\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 13.2354 - val_loss: 18.1135\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 487us/step - loss: 13.1849 - val_loss: 18.1263\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 492us/step - loss: 13.0857 - val_loss: 17.4032\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 13.0644 - val_loss: 17.4300\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 12.9433 - val_loss: 17.5418\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 12.9335 - val_loss: 18.0020\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 12.8143 - val_loss: 17.8487\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 12.8829 - val_loss: 18.4897\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 12.6896 - val_loss: 17.9726\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 494us/step - loss: 12.7261 - val_loss: 18.1095\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 463us/step - loss: 12.6822 - val_loss: 18.1289\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 460us/step - loss: 12.5728 - val_loss: 17.6661\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 4s 469us/step - loss: 12.5588 - val_loss: 17.5613\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 12.5741 - val_loss: 17.7652\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 12.4725 - val_loss: 17.7241\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 12.4022 - val_loss: 17.5913\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 12.4088 - val_loss: 17.2829\n",
      "2410/2410 [==============================] - 1s 245us/step\n",
      "4.2332971267991395\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)  # 输出层，2个神经元对应 x 和 y\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 5s 597us/step - loss: 32012.1816 - val_loss: 1559.0292\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 5s 588us/step - loss: 301.3584 - val_loss: 45.8746\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 583us/step - loss: 31.9268 - val_loss: 35.7359\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 5s 600us/step - loss: 26.9055 - val_loss: 32.4825\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 5s 584us/step - loss: 24.3515 - val_loss: 28.7360\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 581us/step - loss: 22.3432 - val_loss: 26.8934\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 5s 604us/step - loss: 20.9128 - val_loss: 25.1679\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 5s 604us/step - loss: 19.5159 - val_loss: 23.3762\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 18.4508 - val_loss: 22.6567\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 5s 634us/step - loss: 17.5072 - val_loss: 22.3284\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 5s 604us/step - loss: 16.8278 - val_loss: 22.3882\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 5s 603us/step - loss: 16.2861 - val_loss: 21.6397\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 555us/step - loss: 15.9802 - val_loss: 21.2393\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 561us/step - loss: 15.5371 - val_loss: 21.5970\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 556us/step - loss: 15.2331 - val_loss: 20.5822\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 5s 609us/step - loss: 15.0173 - val_loss: 21.2279\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 580us/step - loss: 14.9049 - val_loss: 20.4372\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 14.6368 - val_loss: 20.9040\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 14.5037 - val_loss: 20.5850\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 14.2720 - val_loss: 19.8129\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 550us/step - loss: 14.1399 - val_loss: 19.5689\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 575us/step - loss: 14.0093 - val_loss: 19.3093\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 5s 603us/step - loss: 13.8610 - val_loss: 19.3686\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 5s 598us/step - loss: 13.7952 - val_loss: 19.0340\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 5s 603us/step - loss: 13.6503 - val_loss: 18.3937\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 5s 606us/step - loss: 13.5525 - val_loss: 19.8608\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 5s 599us/step - loss: 13.4580 - val_loss: 18.9956\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 5s 600us/step - loss: 13.3799 - val_loss: 19.2197\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 5s 626us/step - loss: 13.2189 - val_loss: 19.0299\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 5s 657us/step - loss: 13.1705 - val_loss: 18.9163\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 5s 615us/step - loss: 13.1302 - val_loss: 18.7231\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 5s 606us/step - loss: 13.0051 - val_loss: 18.8957\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 5s 609us/step - loss: 12.9463 - val_loss: 18.7920\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 537us/step - loss: 12.8583 - val_loss: 19.1303\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 540us/step - loss: 12.8528 - val_loss: 18.9269\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 545us/step - loss: 12.7734 - val_loss: 19.2714\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 582us/step - loss: 12.6607 - val_loss: 17.7927\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 5s 605us/step - loss: 12.6958 - val_loss: 19.0258\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 5s 630us/step - loss: 12.6786 - val_loss: 18.4720\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 5s 644us/step - loss: 12.5460 - val_loss: 19.0758\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 5s 641us/step - loss: 12.4953 - val_loss: 18.3699\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 5s 641us/step - loss: 12.4303 - val_loss: 18.7158\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 5s 617us/step - loss: 12.3415 - val_loss: 18.3576\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 5s 598us/step - loss: 12.3220 - val_loss: 18.0194\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 5s 610us/step - loss: 12.2767 - val_loss: 17.8967\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 5s 628us/step - loss: 12.2108 - val_loss: 17.8521\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 567us/step - loss: 12.2045 - val_loss: 17.2175\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 570us/step - loss: 12.0994 - val_loss: 18.3717\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 567us/step - loss: 12.1005 - val_loss: 17.5351\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 564us/step - loss: 12.0090 - val_loss: 18.2216\n",
      "2410/2410 [==============================] - 1s 275us/step\n",
      "4.2441048964513985\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)  # 输出层，2个神经元对应 x 和 y\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=160, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4016/4016 [==============================] - 1s 280us/step\n"
     ]
    }
   ],
   "source": [
    "eva_df_scaled = scaler.transform(eva_df)\n",
    "\n",
    "eva_y=model.predict(eva_df_scaled)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('tensor_output1.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.437238934523309\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "eva_df_scaled = scaler.transform(eva_df)\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=550,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=150,random_state=rs)\n",
    "rfr.fit(X_train_scaled, y_train)\n",
    "y_rfr=rfr.predict(X_test_scaled)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df_scaled)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output13.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
